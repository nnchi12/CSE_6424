{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3 - Q3 [35 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Notices\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "    WARNING: <strong>REMOVE</strong> any print statements added to cells with \"#export\" that are used for debugging purposes befrore submitting because they will crash the autograder in Gradescope. Any additional cells can be used for testing purposes at the bottom. \n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "    WARNING: Do <strong>NOT</strong> remove any comment that says \"#export\" because that will crash the autograder in Gradescope. We use this comment to export your code in these cells for grading.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "    WARNING: Do <strong>NOT</strong> import any additional libraries into this workbook.\n",
    "</div>\n",
    "\n",
    "All instructions, code comments, etc. in this notebook **are part of the assignment instructions**. That is, if there is instructions about completing a task in this notebook, that task is not optional.  \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    You <strong>must</strong> implement the following functions in this notebook to receive credit.\n",
    "</div>\n",
    "\n",
    "`user()`\n",
    "\n",
    "`long_trips()`\n",
    "\n",
    "`manhattan_trips()`\n",
    "\n",
    "`weighted_profit()`\n",
    "\n",
    "`final_output()`\n",
    "\n",
    "Each method will be auto-graded using different sets of parameters or data, to ensure that values are not hard-coded.  You may assume we will only use your code to work with data from the NYC-TLC dataset during auto-grading.\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "    WARNING: Do <strong>NOT</strong> remove or modify the following utility functions:\n",
    "</div>\n",
    "\n",
    "`load_data()`\n",
    "\n",
    "`main()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    Do <strong>not</strong> change the below cell. Run it to initialize your PySpark instance. If you don't get any output, make sure your Notebook's Kernel is set to \"PySpark\" in the top right corner.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation started (calculation_id=16c5a340-1cc2-4286-3b8f-3abc485e14cc) in (session=8cc5a30b-da87-6b13-6287-b27c61b4cc1d). Checking calculation status...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66b1a5a06c5943f296ee605a8a6d2b6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress:   0%|          |elapsed time = 00:00s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation completed.\n",
      "<SparkContext master=athena appName=default>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    WARNING: Do <strong>NOT</strong> remodify the below cell. It contains the function for loading data and all imports, and the function for running your code.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation started (calculation_id=f0c5a340-1dea-32e5-8f9e-90e4105a25c9) in (session=8cc5a30b-da87-6b13-6287-b27c61b4cc1d). Checking calculation status...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37cb76824abc42808ef61d12d8bce03d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress:   0%|          |elapsed time = 00:00s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation completed.\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation started (calculation_id=f4c5a340-1f57-6113-28cd-48fd4c0a5615) in (session=8cc5a30b-da87-6b13-6287-b27c61b4cc1d). Checking calculation status...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b12fec437823410fa96a28d79a8e0527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress:   0%|          |elapsed time = 00:00s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation completed.\n"
     ]
    }
   ],
   "source": [
    "#### DO NOT CHANGE ANYTHING IN THIS CELL ####\n",
    "\n",
    "def load_data(size='small'):\n",
    "    # Loads the data for this question. Do not change this function.\n",
    "    # This function should only be called with the parameter 'small' or 'large'\n",
    "    \n",
    "    if size != 'small' and size != 'large':\n",
    "        print(\"Invalid size parameter provided. Use only 'small' or 'large'.\")\n",
    "        return\n",
    "    \n",
    "    input_bucket = \"s3://cse6242-hw3-q3\"\n",
    "    \n",
    "    # Load Trip Data\n",
    "    trip_path = '/'+size+'/yellow_tripdata*'\n",
    "    trips = spark.read.csv(input_bucket + trip_path, header=True, inferSchema=True)\n",
    "    print(\"Trip Count: \",trips.count()) # Prints # of trips (# of records, as each record is one trip)\n",
    "    \n",
    "    # Load Lookup Data\n",
    "    lookup_path = '/'+size+'/taxi*'\n",
    "    lookup = spark.read.csv(input_bucket + lookup_path, header=True, inferSchema=True)\n",
    "    \n",
    "    return trips, lookup\n",
    "\n",
    "def main(size, bucket):\n",
    "    # Runs your functions implemented above.\n",
    "    \n",
    "    print(user())\n",
    "    trips, lookup = load_data(size=size)\n",
    "    trips = long_trips(trips)\n",
    "    mtrips = manhattan_trips(trips, lookup)\n",
    "    wp = weighted_profit(trips, mtrips)\n",
    "    final = final_output(wp, lookup)\n",
    "    \n",
    "    # Outputs the results for you to visually see\n",
    "    final.show()\n",
    "    \n",
    "    # Writes out as a CSV to your bucket.\n",
    "    final.write.csv(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement the below functions for this assignment:\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "    WARNING: Do <strong>NOT</strong> change any function inputs or outputs, and ensure that the dataframes your code returns align with the schema definitions commented in each function. Do <strong>NOT</strong> remove the #export comment from each of the code blocks either. This can prevent your code from being converted to a python file.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a. [1 pt] Update the `user()` function\n",
    "This function should return your GT username, eg: gburdell3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation started (calculation_id=12c5a340-2078-9539-eca1-432f64e96008) in (session=8cc5a30b-da87-6b13-6287-b27c61b4cc1d). Checking calculation status...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7da995fa6df495d91dace51127a4024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress:   0%|          |elapsed time = 00:00s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation completed.\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "def user():\n",
    "    # Returns a string consisting of your GT username.\n",
    "    return 'nchi7'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b. [2 pts] Update the `long_trips()` function\n",
    "This function filters trips to keep only trips greater than or equal to 2 miles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation started (calculation_id=1ec5a340-21d2-5468-1542-e0bfaf93d92d) in (session=8cc5a30b-da87-6b13-6287-b27c61b4cc1d). Checking calculation status...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "283b0e618c3548c09430040a12afa6f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress:   0%|          |elapsed time = 00:00s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation completed.\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "def long_trips(trips):\n",
    "    \n",
    "    # Returns a Dataframe (trips) with Schema the same as :trips:\n",
    "    \n",
    "    from pyspark.sql.functions import col\n",
    "    trips = trips.filter(col(\"trip_distance\") >= 2)\n",
    "    \n",
    "    return trips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3c. [6 pts] Update the `manhattan_trips()` function\n",
    "\n",
    "This function determines the top 20 locations with a `DOLocationID` in manhattan by passenger_count (pcount).\n",
    "\n",
    "Example output formatting:\n",
    "\n",
    "```\n",
    "+--------------+--------+\n",
    "| DOLocationID | pcount |\n",
    "+--------------+--------+\n",
    "|             5|      15|\n",
    "|            16|      12| \n",
    "+--------------+--------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation started (calculation_id=a0c5a340-2325-9f85-a2af-cf7baa615e02) in (session=8cc5a30b-da87-6b13-6287-b27c61b4cc1d). Checking calculation status...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7b8d5db4c4d4abfbefc51cfb355b733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress:   0%|          |elapsed time = 00:00s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation completed.\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "def manhattan_trips(trips, lookup):\n",
    "    # Returns a Dataframe (mtrips) with Schema: DOLocationID, pcount\n",
    "    from pyspark.sql import SparkSession\n",
    "    from pyspark.sql.functions import col, sum\n",
    "    from pyspark.sql.window import Window\n",
    "    from pyspark.sql import functions as F\n",
    "    \n",
    "    # Filter trips with DOLocationID in Manhattan\n",
    "    manhattan_trips_df = trips.join(lookup, trips.DOLocationID == lookup.LocationID, \"inner\").filter(lookup.Borough == \"Manhattan\")\n",
    "\n",
    "    # Group by DOLocationID and sum passenger count\n",
    "    manhattan_trip_agg = manhattan_trips_df.groupBy(\"DOLocationID\").agg(sum(\"passenger_count\").alias(\"pcount\"))\n",
    "\n",
    "    # Rank the locations by passenger count in descending order\n",
    "    windowSpec = Window.orderBy(F.desc(\"pcount\"))\n",
    "    manhattan_trip_agg = manhattan_trip_agg.withColumn(\"rank\", F.rank().over(windowSpec))\n",
    "\n",
    "    # Select the top 20 locations\n",
    "    mtrips = manhattan_trip_agg.filter(col(\"rank\") <= 20).drop(\"rank\")\n",
    "    \n",
    "    return mtrips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3d. [6 pts] Update the `weighted_profit()` function\n",
    "This function should determine the average `total_amount`, the total count of trips, and the total count of trips ending in the top 20 destinations and return the `weighted_profit` as discussed in the homework document.\n",
    "\n",
    "Example output formatting:\n",
    "```\n",
    "+--------------+-------------------+\n",
    "| PULocationID |  weighted_profit  |\n",
    "+--------------+-------------------+\n",
    "|            18| 33.784444421924436| \n",
    "|            12| 21.124577637149223| \n",
    "+--------------+-------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation started (calculation_id=60c5a340-2476-5fe6-6b1d-fd4cc5e78493) in (session=8cc5a30b-da87-6b13-6287-b27c61b4cc1d). Checking calculation status...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd1e669863274fb2acf091e5ae5d1349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress:   0%|          |elapsed time = 00:00s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation completed.\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "def weighted_profit(trips, mtrips): \n",
    "    # Returns a Dataframe (wp) with Schema: PULocationID, weighted_profit\n",
    "    # Note: Use decimal datatype for weighted profit (NOTE: DON'T USE FLOAT)\n",
    "    # Our grader will be only be checking the first 8 characters for each value in the dataframe\n",
    "    \n",
    "    from pyspark.sql.functions import col, avg, count, when, lit\n",
    "    from pyspark.sql.types import DecimalType\n",
    "    \n",
    "    mtrips = mtrips.withColumnRenamed(\"DOLocationID\", \"M_DOLocationID\")\n",
    "    \n",
    "    wp = trips.join(mtrips, trips['DOLocationID'] == mtrips['M_DOLocationID'], \"left\")\n",
    "    \n",
    "    # Calculate the weighted profit for each PULocationID\n",
    "    wp = wp.groupBy(\"PULocationID\").agg(avg(\"total_amount\").alias(\"avg_total_amount\"),count(\"*\").alias(\"total_trips\"),\n",
    "        sum(when(col(\"M_DOLocationID\").isNotNull(), 1)).alias(\"trips_to_top20\"))\n",
    "\n",
    "    # Calculate the weighted profit using the formula\n",
    "    wp = wp.withColumn(\"weighted_profit\",(col(\"trips_to_top20\") / col(\"total_trips\"))*col(\"avg_total_amount\").cast(DecimalType(38, 18)))\n",
    "    \n",
    "    # Select only the relevant columns\n",
    "    wp = wp.select(\"PULocationID\", \"weighted_profit\")\n",
    "    \n",
    "    return wp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3e. [5 pts] Update the `final_output()` function\n",
    "This function will take the results of `weighted_profit`, links it to the `borough` and `zone` and returns the top 20 locations with the highest `weighted_profit`.\n",
    "\n",
    "Example output formatting:\n",
    "```\n",
    "+------------+---------+-------------------+\n",
    "|    Zone    | Borough |  weighted_profit  |\n",
    "+----------------------+-------------------+\n",
    "| JFK Airport|   Queens|  16.95897820117925|\n",
    "|     Jamaica|   Queens| 14.879835188762488|\n",
    "+------------+---------+-------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation started (calculation_id=36c5a340-2587-5666-cb1a-3a6f97f6103a) in (session=8cc5a30b-da87-6b13-6287-b27c61b4cc1d). Checking calculation status...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f274f32ac3d4aacbdddaada9eeedcfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress:   0%|          |elapsed time = 00:00s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation completed.\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "def final_output(wp, lookup): \n",
    "    # Returns a Dataframe (final) with Schema: Zone, Borough, weighted_profit\n",
    "    # Note: Use decimal datatype for weighted profit (NOTE: DON'T USE FLOAT)\n",
    "    # Our grader will be only be checking the first 8 characters for each value in the dataframe\n",
    "    \n",
    "    from pyspark.sql import functions as F\n",
    "    from pyspark.sql.types import StructType, StructField, StringType, DecimalType\n",
    "    # Join the wp (weighted_profit) DataFrame with the lookup DataFrame to get zone and borough information\n",
    "    final = wp.join(lookup, wp.PULocationID == lookup.LocationID, \"inner\").select(\"Zone\", \"Borough\", \"weighted_profit\")\n",
    "\n",
    "    # Rank the locations by weighted profit in descending order\n",
    "    windowSpec = Window.orderBy(F.desc(\"weighted_profit\"))\n",
    "    final = final.withColumn(\"rank\", F.rank().over(windowSpec))\n",
    "\n",
    "    # Select the top 20 locations with the highest weighted profit\n",
    "    final = final.filter(col(\"rank\") <= 20).drop(\"rank\")  \n",
    "    \n",
    "    from pyspark.sql.types import DecimalType\n",
    "    final = final.select(final[\"Zone\"].cast(StringType()).alias(\"Zone\"),final[\"Borough\"].cast(StringType()).alias(\"Borough\"), final[\"weighted_profit\"].cast(DecimalType(38, 10)).alias(\"weighted_profit\"))\n",
    "    \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation started (calculation_id=2cc5a340-26aa-8353-5c78-2f5b6c44e2b3) in (session=8cc5a30b-da87-6b13-6287-b27c61b4cc1d). Checking calculation status...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cdf30e924b24cb5b4d080cf8a971aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress:   0%|          |elapsed time = 00:00s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation completed.\n",
      "nchi7\n",
      "Trip Count:  187203269\n",
      "+--------------------+-------------+---------------+\n",
      "|                Zone|      Borough|weighted_profit|\n",
      "+--------------------+-------------+---------------+\n",
      "|        Baisley Park|       Queens|  29.3604557791|\n",
      "|Flushing Meadows-...|       Queens|  27.3048457336|\n",
      "|       South Jamaica|       Queens|  26.2949162399|\n",
      "|     Randalls Island|    Manhattan|  24.1509899402|\n",
      "|        Astoria Park|       Queens|  21.7064171121|\n",
      "|Briarwood/Jamaica...|       Queens|  19.9450646318|\n",
      "|Springfield Garde...|       Queens|  19.4683092888|\n",
      "|             Jamaica|       Queens|  19.2839430001|\n",
      "|              Corona|       Queens|  18.2287692482|\n",
      "|   LaGuardia Airport|       Queens|  18.1813388084|\n",
      "|         Jamaica Bay|       Queens|  17.1005294468|\n",
      "|             Maspeth|       Queens|  17.0054506401|\n",
      "|Eltingville/Annad...|Staten Island|  16.8377647569|\n",
      "|         JFK Airport|       Queens|  16.7777253482|\n",
      "|        Battery Park|    Manhattan|  12.8497803111|\n",
      "| Morningside Heights|    Manhattan|  12.4536980266|\n",
      "|   Battery Park City|    Manhattan|  12.4488484044|\n",
      "|Greenwich Village...|    Manhattan|  12.4469498917|\n",
      "|       Rikers Island|        Bronx|  12.3063000000|\n",
      "|  World Trade Center|    Manhattan|  12.2954119241|\n",
      "+--------------------+-------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main(size='large', bucket = 's3://cse6242-nchi7/q3-output-large12')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    You may use the below cell for any additional testing you need to do, however any code implemented below will not be run or used when grading.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trips.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "manhattan_trips(trips, lookup).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "weighted_profit(trips,mtrips).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "final_output(wp, lookup).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Athena PySpark",
   "language": "python",
   "name": "kepler_python_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "Python_Session",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
